{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import zeros, int8, log\n",
    "from pylab import random\n",
    "import re\n",
    "import time\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(dataset, stopwords):\n",
    "    file = codecs.open(stopwords, 'r', 'utf-8')\n",
    "    sw = [line.strip() for line in file] \n",
    "    file.close()\n",
    "    file = codecs.open(dataset, 'r', 'utf-8')\n",
    "    documents = [document.strip() for document in file] \n",
    "    file.close()\n",
    "\n",
    "    len_doc = len(documents)\n",
    "    word_counts = [];\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    init_id = 0;\n",
    "    \n",
    "    for document in documents:\n",
    "        word_count = {}\n",
    "        for word in document:\n",
    "            word = word.lower().strip()\n",
    "            if len(word) > 1 and not re.search('[0-9]', word) and word not in sw:               \n",
    "                if word not in word_to_id.keys():\n",
    "                    word_to_id[word] = init_id;\n",
    "                    id_to_word[init_id] = word;\n",
    "                    init_id += 1;\n",
    "                if word in word_counts:\n",
    "                    word_count[word] += 1\n",
    "                else:\n",
    "                    word_count[word] = 1\n",
    "        word_counts.append(word_count);\n",
    "    \n",
    "    len_word_to_id = len(word_to_id)  \n",
    "    X = zeros([len_doc, len_word_to_id], int8)\n",
    "    \n",
    "    for word in word_to_id.keys():\n",
    "        j = word_to_id[word]\n",
    "        for i in range(0, len_doc):\n",
    "            if word in word_counts[i]:\n",
    "                X[i, j] = word_counts[i][word];    \n",
    "\n",
    "    return len_doc, len_word_to_id, word_to_id, id_to_word, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeParameters():\n",
    "    for i in range(0, N):\n",
    "        normalization = sum(lamda[i, :])\n",
    "        for j in range(0, K):\n",
    "            lamda[i, j] /= normalization;\n",
    "\n",
    "    for i in range(0, K):\n",
    "        normalization = sum(theta[i, :])\n",
    "        for j in range(0, M):\n",
    "            theta[i, j] /= normalization;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logLikelihood():\n",
    "    log_l = 0\n",
    "    for i in range(0, N):\n",
    "        for j in range(0, M):\n",
    "            tmp = 0\n",
    "            for k in range(0, K):\n",
    "                tmp += theta[k, j] * lamda[i, k]\n",
    "            if tmp > 0:\n",
    "                log_l += X[i, j] * log(tmp)\n",
    "    return log_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eStep():\n",
    "    for i in range(0, N):\n",
    "        for j in range(0, M):\n",
    "            denom = 0;\n",
    "            for k in range(0, K):\n",
    "                p[i, j, k] = theta[k, j] * lamda[i, k];\n",
    "                denom += p[i, j, k];\n",
    "            if denom == 0:\n",
    "                for k in range(0, K):\n",
    "                    p[i, j, k] = 0;\n",
    "            else:\n",
    "                for k in range(0, K):\n",
    "                    p[i, j, k] /= denom;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mStep():\n",
    "    for i in range(0, N):\n",
    "        for k in range(0, K):\n",
    "            lamda[i, k] = 0\n",
    "            denom = 0\n",
    "            for j in range(0, M):\n",
    "                lamda[i, k] += X[i, j] * p[i, j, k]\n",
    "                denom += X[i, j];\n",
    "            if denom == 0:\n",
    "                lamda[i, k] = 1.0 / K\n",
    "            else:\n",
    "                lamda[i, k] /= denom\n",
    "                \n",
    "    for k in range(0, K):\n",
    "        denom = 0\n",
    "        for j in range(0, M):\n",
    "            theta[k, j] = 0\n",
    "            for i in range(0, N):\n",
    "                theta[k, j] += X[i, j] * p[i, j, k]\n",
    "            denom += theta[k, j]\n",
    "        if denom == 0:\n",
    "            for j in range(0, M):\n",
    "                theta[k, j] = 1.0 / M\n",
    "        else:\n",
    "            for j in range(0, M):\n",
    "                theta[k, j] /= denom    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result():\n",
    "    file = codecs.open(dictionary,'w','utf-8')\n",
    "    for i in range(0, M):\n",
    "        file.write(id2word[i] + '\\n')\n",
    "    file.close()\n",
    "    \n",
    "    file = codecs.open(topWords,'w','utf-8')\n",
    "    for i in range(0, K):\n",
    "        topics = []\n",
    "        ids = theta[i, :].argsort()\n",
    "        for j in ids:\n",
    "            topics.insert(0, id2word[j])\n",
    "        tmp = ''\n",
    "        for word in topics[0:min(topicWordsNum, len(topics))]:\n",
    "            tmp += word + ' '\n",
    "        file.write(tmp + '\\n')\n",
    "    file.close()\n",
    "        \n",
    "    file = codecs.open(docTopicDistDistribution,'w','utf-8')\n",
    "    for i in range(0, N):\n",
    "        tmp = ''\n",
    "        for j in range(0, K):\n",
    "            tmp += str(lamda[i, j]) + ' '\n",
    "        file.write(tmp + '\\n')\n",
    "    file.close()\n",
    "    \n",
    "    file = codecs.open(topicWordDistribution,'w','utf-8')\n",
    "    for i in range(0, K):\n",
    "        tmp = ''\n",
    "        for j in range(0, M):\n",
    "            tmp += str(theta[i, j]) + ' '\n",
    "        file.write(tmp + '\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Ospan\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.745 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-12-27 22:02:26 ]  1  iteration   -147485.621660961\n",
      "[ 2020-12-27 22:03:16 ]  2  iteration   -145296.73814273378\n",
      "[ 2020-12-27 22:04:06 ]  3  iteration   -142487.00182718155\n",
      "[ 2020-12-27 22:04:59 ]  4  iteration   -139216.32777316848\n",
      "[ 2020-12-27 22:05:54 ]  5  iteration   -135913.96495237478\n",
      "[ 2020-12-27 22:06:50 ]  6  iteration   -133017.4139328115\n",
      "[ 2020-12-27 22:07:44 ]  7  iteration   -130727.37988343116\n",
      "[ 2020-12-27 22:08:37 ]  8  iteration   -129025.38435876224\n",
      "[ 2020-12-27 22:09:29 ]  9  iteration   -127775.20275849756\n",
      "[ 2020-12-27 22:10:21 ]  10  iteration   -126827.7694353583\n",
      "[ 2020-12-27 22:11:12 ]  11  iteration   -126100.24492361289\n",
      "[ 2020-12-27 22:12:07 ]  12  iteration   -125517.76741863204\n",
      "[ 2020-12-27 22:13:00 ]  13  iteration   -125053.88031924044\n",
      "[ 2020-12-27 22:13:51 ]  14  iteration   -124696.47202140526\n",
      "[ 2020-12-27 22:14:43 ]  15  iteration   -124421.87665048064\n",
      "[ 2020-12-27 22:15:38 ]  16  iteration   -124225.73797153155\n",
      "[ 2020-12-27 22:16:41 ]  17  iteration   -124086.5066781454\n",
      "[ 2020-12-27 22:17:47 ]  18  iteration   -123986.35619879319\n",
      "[ 2020-12-27 22:18:38 ]  19  iteration   -123909.93496005441\n",
      "[ 2020-12-27 22:19:28 ]  20  iteration   -123850.81962111575\n",
      "[ 2020-12-27 22:20:18 ]  21  iteration   -123811.36111425454\n",
      "[ 2020-12-27 22:21:10 ]  22  iteration   -123786.05709658291\n",
      "[ 2020-12-27 22:22:03 ]  23  iteration   -123764.18007801441\n",
      "[ 2020-12-27 22:22:57 ]  24  iteration   -123748.91347192049\n",
      "[ 2020-12-27 22:23:46 ]  25  iteration   -123736.64505386818\n",
      "[ 2020-12-27 22:24:38 ]  26  iteration   -123726.08810017795\n",
      "[ 2020-12-27 22:25:29 ]  27  iteration   -123717.1367863637\n"
     ]
    }
   ],
   "source": [
    "dataset = 'dataset.txt'\n",
    "stopwords = 'stopwords.dic'\n",
    "\n",
    "docTopicDistDistribution = 'docTopicDistribution.txt'\n",
    "topicWordDistribution = 'topicWordDistribution.txt'\n",
    "dictionary = 'dictionary.dic'\n",
    "topWords = 'topics.txt'\n",
    "\n",
    "N = 5\n",
    "maxIteration = 25\n",
    "threshold = 5.0\n",
    "topicWordsNum = 5\n",
    "    \n",
    "# preprocessing\n",
    "len_doc, len_word_to_id, word_to_id, id_to_word, X = preProcessing(dataset, stopwords)\n",
    "\n",
    "# lamda[i, j]=>p(zj|di)\n",
    "lamda = random([len_doc, N])\n",
    "\n",
    "# theta[i, j]=>p(wj|zi)\n",
    "theta = random([N, len_word_to_id])\n",
    "\n",
    "# p[i, j, k]=>p(zk|di,wj)\n",
    "p = zeros([len_doc, len_word_to_id, N])\n",
    "\n",
    "initializeParameters()\n",
    "oldLoglikelihood = 1\n",
    "newLoglikelihood = 1\n",
    "for i in range(0, maxIteration):\n",
    "    eStep()\n",
    "    mStep()\n",
    "    newLoglikelihood = logLikelihood()\n",
    "    print(\"[\", time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())), \"] \", i+1, \" iteration  \", str(newLoglikelihood))\n",
    "    if((newLoglikelihood - oldLoglikelihood) < thresholdold and Loglikelihood != 1):\n",
    "        break\n",
    "    oldLoglikelihood = newLoglikelihood\n",
    "\n",
    "result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
